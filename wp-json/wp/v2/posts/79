{"id":79,"date":"2019-12-29T19:05:45","date_gmt":"2019-12-29T18:05:45","guid":{"rendered":"https:\/\/machinelearningspace.com\/?p=79"},"modified":"2022-10-30T00:36:55","modified_gmt":"2022-10-29T22:36:55","slug":"yolov3-tensorflow-2-part-3","status":"publish","type":"post","link":"https:\/\/machinelearningspace.com\/yolov3-tensorflow-2-part-3\/","title":{"rendered":"The beginner\u2019s guide to implementing YOLOv3 in TensorFlow 2.0 (part-3)"},"content":{"rendered":"\n<p><div class=\"responsive-embed-container\">\n<iframe loading=\"lazy\" width=\"560\" height=\"315\" src=\"https:\/\/www.youtube.com\/embed\/ZOt1q3aCIIA\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>\n<\/div><\/p>\n\n\n\n<p><a href=\"https:\/\/machinelearningspace.com\/yolov3-tensorflow-2-part-2\/\">In part 2<\/a>, we&#8217;ve discovered how to construct the YOLOv3 network.  In this part 3, we&#8217;ll focus on the file <code>yolov3.weights<\/code>.<\/p>\n\n\n\n<p>So, what we&#8217;re going to do in part is to load the weights parameters from the file <code>yolov3.weights<\/code>, then convert them into the TensorFlow 2.0 weights format.  Just to remain you that, the file <code>yolov3.weights<\/code> contains the pre-trained CNN&#8217;s parameters of YOLOv3.<\/p>\n\n\n\n<p>To begin with, let&#8217;s take a look at how the YOLOv3 weights are stored.<\/p>\n\n\n\n<h3 id=\"understandingtheweightsfile\">How YOLOv3&#8217;s weights are stored?<\/h3>\n\n\n\n<p>The original YOLOv3 weights file <code>yolov3.weights<\/code>  is a binary file and the weights are stored in the float data type. <\/p>\n\n\n\n<p>One thing that we need to know that the weights only belong to convolutional layers. As we know, in YOLOv3, there are 2  convolutional layer types, with and without a batch normalization layer. So,  the weights are applied differently for different types of convolutional layers.  Since we&#8217;re reading the only float data, there&#8217;s no clue which one belongs to which layer.  If we incorrectly associate these weights with their layers properly, we&#8217;ll screw up everything, and the weights won&#8217;t be converted. So, that&#8217;s why understanding how the weights are stored is crucially important.  <\/p>\n\n\n\n<p>Here, I tried to make a simple flowchart in order to describe how the weights are stored. <\/p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large is-resized\"><img decoding=\"async\" loading=\"lazy\" src=\"https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/weights.jpg\" alt=\"\" class=\"wp-image-529\" width=\"444\" height=\"436\" srcset=\"https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/weights.jpg 562w, https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/weights-300x295.jpg 300w, https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/weights-305x300.jpg 305w\" sizes=\"(max-width: 444px) 100vw, 444px\" \/><\/figure><\/div>\n\n\n<p>When we re-write these weights to TensorFlow&#8217;s format  for a convolutional with a batch normalization layer, we need to switch the position of <code>beta<\/code> and <code>gamma<\/code>. So, they&#8217;re ordered like this: <code>beta<\/code>, <code>gamma<\/code>, <code>means<\/code>, <code>variance <\/code>and <code>conv weights<\/code>.  However,  the weights&#8217; order remains the same for the convolutional without a batch normalization layer.<\/p>\n\n\n\n<p>All right!!, Now we&#8217;re ready to code the weights converter. <\/p>\n\n\n\n<p>Without further ado, let&#8217;s do it&#8230;<\/p>\n\n\n\n<h3>Working with the file <code>convert_weights.py<\/code><\/h3>\n\n\n\n<p>Open the file <code>convert_weights.py<\/code>, then copy and paste the following code to the top of it. Here, we import NumPy library and the two functions that we&#8217;ve created previously in part 2, <code>YOLOv3Net<\/code> and <code>parse_cfg<\/code>.<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"atomic\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"1\" data-enlighter-title=\"\" data-enlighter-group=\"\">#convert_weights.py\nimport numpy as np\nfrom yolov3 import YOLOv3Net\nfrom yolov3 import parse_cfg<\/pre>\n\n\n\n<p>Now, let&#8217;s create a function called <code>load_weights()<\/code>. This function has 3 parameters, <code>model<\/code>, <code>cfgfile<\/code>, and <code>weightfile<\/code>. The parameter <code>model<\/code> is a returning parameters of the network&#8217;s model after calling the function <code>YOLOv3Net<\/code>.  The<code>cfgfile<\/code> and <code>weightfile<\/code> are respectively refer to the files <code>yolov3.cfg<\/code> and <code>yolov3.weights<\/code>.<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"atomic\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"6\" data-enlighter-title=\"\" data-enlighter-group=\"\">def load_weights(model,cfgfile,weightfile):<\/pre>\n\n\n\n<p>Open the file  <code>yolov3.weights<\/code> and read the first 5 values. These values are the header information. So, we can skip them all.<br><\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"atomic\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"7\" data-enlighter-title=\"\" data-enlighter-group=\"\">    # Open the weights file\n    fp = open(weightfile, \"rb\")\n\n    # The first 5 values are header information\n    np.fromfile(fp, dtype=np.int32, count=5)<\/pre>\n\n\n\n<p>Then call <code>parse_cfg()<\/code> function.<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"atomic\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"14\" data-enlighter-title=\"\" data-enlighter-group=\"\">    blocks = parse_cfg(cfgfile)<\/pre>\n\n\n\n<p>As we did when building the YOLOv3 network, we need to loop over the <code>blocks<\/code> and search for the convolutional layer. Don&#8217;t forget to check whether the convolutional is with batch normalization or not. If it is true, go get the relevant values (<code>gamma<\/code>, <code>beta<\/code>, <code>means<\/code>, and <code>variance<\/code>), and re-arrange them to the TensorFlow weights order. Otherwise, take the bias values. After that take the convolutional weights and set these weights to the convolutional layer depending on the convolutional type.<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"atomic\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"16\" data-enlighter-title=\"\" data-enlighter-group=\"\">    for i, block in enumerate(blocks[1:]):\n\n        if (block[\"type\"] == \"convolutional\"):\n            conv_layer = model.get_layer('conv_' + str(i))\n            print(\"layer: \",i+1,conv_layer)\n\n            filters = conv_layer.filters\n            k_size = conv_layer.kernel_size[0]\n            in_dim = conv_layer.input_shape[-1]\n\n            if \"batch_normalize\" in block:\n\n                norm_layer = model.get_layer('bnorm_' + str(i))\n                print(\"layer: \",i+1,norm_layer)\n                size = np.prod(norm_layer.get_weights()[0].shape)\n\n                bn_weights = np.fromfile(fp, dtype=np.float32, count=4 * filters)\n                # tf [gamma, beta, mean, variance]\n                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n\n            else:\n                conv_bias = np.fromfile(fp, dtype=np.float32, count=filters)\n\n            # darknet shape (out_dim, in_dim, height, width)\n            conv_shape = (filters, in_dim, k_size, k_size)\n            conv_weights = np.fromfile(\n                fp, dtype=np.float32, count=np.product(conv_shape))\n            # tf shape (height, width, in_dim, out_dim)\n            conv_weights = conv_weights.reshape(\n                conv_shape).transpose([2, 3, 1, 0])\n\n            if \"batch_normalize\" in block:\n                norm_layer.set_weights(bn_weights)\n                conv_layer.set_weights([conv_weights])\n            else:\n                conv_layer.set_weights([conv_weights, conv_bias])<\/pre>\n\n\n\n<p>Alert if the reading has failed. Then, close the file whether the reading was successful or not.<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"atomic\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"53\" data-enlighter-title=\"\" data-enlighter-group=\"\">    assert len(fp.read()) == 0, 'failed to read all data'\n    fp.close()<\/pre>\n\n\n\n<p>The last part of this code is the main function. Copy and paste the following code of the main function just right after the function <code>load_weights()<\/code>. <\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"python\" data-enlighter-theme=\"atomic\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"57\" data-enlighter-title=\"\" data-enlighter-group=\"\">def main():\n\n    weightfile = \"weights\/yolov3.weights\"\n    cfgfile = \"cfg\/yolov3.cfg\"\n\n    model_size = (416, 416, 3)\n    num_classes = 80\n\n    model=YOLOv3Net(cfgfile,model_size,num_classes)\n    load_weights(model,cfgfile,weightfile)\n\n    try:\n        model.save_weights('weights\/yolov3_weights.tf')\n        print('\\nThe file \\'yolov3_weights.tf\\' has been saved successfully.')\n    except IOError:\n        print(\"Couldn't write the file \\'yolov3_weights.tf\\'.\")<\/pre>\n\n\n\n<p>Here is the complete code for the  <code>convert_weights.py<\/code> <\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"generic\" data-enlighter-theme=\"atomic\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">#convert_weights.py\nimport numpy as np\nfrom yolov3 import YOLOv3Net\nfrom yolov3 import parse_cfg\n\ndef load_weights(model,cfgfile,weightfile):\n    # Open the weights file\n    fp = open(weightfile, \"rb\")\n\n    # Skip 5 header values\n    np.fromfile(fp, dtype=np.int32, count=5)\n\n    # The rest of the values are the weights\n    blocks = parse_cfg(cfgfile)\n\n    for i, block in enumerate(blocks[1:]):\n\n        if (block[\"type\"] == \"convolutional\"):\n            conv_layer = model.get_layer('conv_' + str(i))\n            print(\"layer: \",i+1,conv_layer)\n\n            filters = conv_layer.filters\n            k_size = conv_layer.kernel_size[0]\n            in_dim = conv_layer.input_shape[-1]\n\n            if \"batch_normalize\" in block:\n\n                norm_layer = model.get_layer('bnorm_' + str(i))\n                print(\"layer: \",i+1,norm_layer)\n                size = np.prod(norm_layer.get_weights()[0].shape)\n\n                bn_weights = np.fromfile(fp, dtype=np.float32, count=4 * filters)\n                # tf [gamma, beta, mean, variance]\n                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n\n            else:\n                conv_bias = np.fromfile(fp, dtype=np.float32, count=filters)\n\n            # darknet shape (out_dim, in_dim, height, width)\n            conv_shape = (filters, in_dim, k_size, k_size)\n            conv_weights = np.fromfile(\n                fp, dtype=np.float32, count=np.product(conv_shape))\n            # tf shape (height, width, in_dim, out_dim)\n            conv_weights = conv_weights.reshape(\n                conv_shape).transpose([2, 3, 1, 0])\n\n            if \"batch_normalize\" in block:\n                norm_layer.set_weights(bn_weights)\n                conv_layer.set_weights([conv_weights])\n            else:\n                conv_layer.set_weights([conv_weights, conv_bias])\n\n    assert len(fp.read()) == 0, 'failed to read all data'\n    fp.close()\n\n\ndef main():\n\n    weightfile = \"weights\/yolov3.weights\"\n    cfgfile = \"cfg\/yolov3.cfg\"\n\n    model_size = (416, 416, 3)\n    num_classes = 80\n\n    model=YOLOv3Net(cfgfile,model_size,num_classes)\n    load_weights(model,cfgfile,weightfile)\n\n    try:\n        model.save_weights('weights\/yolov3_weights.tf')\n        print('\\nThe file \\'yolov3_weights.tf\\' has been saved successfully.')\n    except IOError:\n        print(\"Couldn't write the file \\'yolov3_weights.tf\\'.\")\n\n\nif __name__ == '__main__':\n    main()<\/pre>\n\n\n\n<p>Finally, we can now execute the  <code>convert_weights.py<\/code> file . Open  Anaconda prompt or terminal in Pycharm, type the following command and press Enter.<\/p>\n\n\n\n<pre class=\"EnlighterJSRAW\" data-enlighter-language=\"generic\" data-enlighter-theme=\"\" data-enlighter-highlight=\"\" data-enlighter-linenumbers=\"false\" data-enlighter-lineoffset=\"\" data-enlighter-title=\"\" data-enlighter-group=\"\">python convert_weights.py<\/pre>\n\n\n\n<p>Here is the output, I printed all the convolutional layers just to make sure that the weights are loaded correctly until the last convolutional layer.<\/p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"1089\" height=\"937\" src=\"https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights-3.png\" alt=\"\" class=\"wp-image-592\" srcset=\"https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights-3.png 1089w, https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights-3-300x258.png 300w, https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights-3-1024x881.png 1024w, https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights-3-768x661.png 768w, https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights-3-349x300.png 349w\" sizes=\"(max-width: 1089px) 100vw, 1089px\" \/><\/figure><\/div>\n\n\n<p>If you use PyCharm, look at the Project Navigation on the left side as I pointed with the red boxes, you have 4 new files:<\/p>\n\n\n\n<ul><li>checkpoint<\/li><li>yolov3_weights.tf.data-00000-of-00002<\/li><li>yolov3_weights.tf.data-00001-of-00002<\/li><li>yolov3_weights.tf.index<\/li><\/ul>\n\n\n\n<p>Those files are the TensorFlow 2.0 weights format. So, anytime we want to use them, just simply call them like the only one file,  <code>yolov3_weights.tf<\/code>. We&#8217;ll see how to do this in the last part of this tutorial. <\/p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"1357\" height=\"819\" src=\"https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights_2.png\" alt=\"\" class=\"wp-image-594\" srcset=\"https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights_2.png 1357w, https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights_2-300x181.png 300w, https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights_2-1024x618.png 1024w, https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights_2-768x464.png 768w, https:\/\/machinelearningspace.com\/wp-content\/uploads\/2020\/01\/conv_weights_2-497x300.png 497w\" sizes=\"(max-width: 1357px) 100vw, 1357px\" \/><\/figure><\/div>\n\n\n<p>This is the end of part 3, and we still have several things to do, those are: <\/p>\n\n\n\n<ul><li>creating a pipeline to read the input image or video\/camera, <\/li><li>computing the prediction, <\/li><li>and drawing the bounding boxes prediction over the input image\/video\/camera. <\/li><\/ul>\n\n\n\n<p>Those are what we will be doing soon in the <a href=\"https:\/\/machinelearningspace.com\/yolov3-tensorflow-2-part-4\/\">last part<\/a>. Let&#8217;s go into it&#8230;<\/p>\n\n\n\n<h2>Parts<\/h2>\n\n\n\n<ul>\n<li><p><a href=\"https:\/\/machinelearningspace.com\/yolov3-tensorflow-2-part-1\/\">Part-1, An introduction of the YOLOv3 algorithm.<\/a><\/p>\n<\/li>\n<li><p><a href=\"https:\/\/machinelearningspace.com\/yolov3-tensorflow-2-part--2\/\">Part-2, Parsing the YOLOv3 configuration file and creating the YOLOv3 network.<\/a><\/p>\n<\/li>\n<li><p><a href=\"https:\/\/machinelearningspace.com\/yolov3-tensorflow-2-part-3\/\">Part-3, Converting the YOLOv3 pre-trained weights into the TensorFlow 2.0 weights format.<\/a><\/p>\n<\/li>\n<li><p><a href=\"https:\/\/machinelearningspace.com\/yolov3-tensorflow-2-part-4\/\">Part-4, Encoding bounding boxes and testing this implementation with images and videos. <\/a><\/p>\n<\/li>\n<\/ul>\n","protected":false},"excerpt":{"rendered":"<p>In part 2, we&#8217;ve discovered how to construct the YOLOv3 network. In this part 3, we&#8217;ll focus on the file yolov3.weights. So, what we&#8217;re going to do in part is to load the weights parameters from the file yolov3.weights, then convert them into the TensorFlow 2.0 weights format. Just to remain you that, the file [&hellip;]<\/p>\n","protected":false},"author":2,"featured_media":569,"comment_status":"open","ping_status":"closed","sticky":false,"template":"","format":"standard","meta":{"_mi_skip_tracking":false},"categories":[2,4,6,3],"tags":[87,47,24,25,28],"_links":{"self":[{"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/posts\/79"}],"collection":[{"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/users\/2"}],"replies":[{"embeddable":true,"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/comments?post=79"}],"version-history":[{"count":5,"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/posts\/79\/revisions"}],"predecessor-version":[{"id":3100,"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/posts\/79\/revisions\/3100"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/media\/569"}],"wp:attachment":[{"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/media?parent=79"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/categories?post=79"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/machinelearningspace.com\/wp-json\/wp\/v2\/tags?post=79"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}